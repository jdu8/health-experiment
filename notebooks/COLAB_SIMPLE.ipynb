{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Chatbot Experiment - Simple Colab Version\n",
    "\n",
    "This is a simplified version that fixes the import errors.\n",
    "\n",
    "**Setup:**\n",
    "1. Runtime → Change runtime type → GPU\n",
    "2. Run cells in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone Repo & Fix Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (update URL with your repo)\n",
    "!git clone https://github.com/yourusername/health-experiment.git\n",
    "%cd health-experiment\n",
    "\n",
    "# CRITICAL: Fix Python path so imports work\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"✓ Setup complete\")\n",
    "print(f\"  Directory: {project_root}\")\n",
    "print(f\"  src exists: {(project_root / 'src').exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch and LLM libraries\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q transformers>=4.35.0 accelerate>=0.24.0\n",
    "!pip install -q bitsandbytes>=0.41.0 sentencepiece>=0.1.99\n",
    "!pip install -q pyyaml numpy pandas python-dateutil tqdm\n",
    "\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU CHECK\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(\"\\n✓ GPU ready for LLMs!\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No GPU detected!\")\n",
    "    print(\"Go to: Runtime → Change runtime type → GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Import (Should Work Now!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.simulation import MedicalChatbotSimulation\n",
    "\n",
    "print(\"✓ Import successful!\")\n",
    "print(\"  All src modules are accessible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Simulation with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing simulation...\")\n",
    "print(\"(First time: downloads models, takes 5-10 minutes)\\n\")\n",
    "\n",
    "sim = MedicalChatbotSimulation(\n",
    "    config_path=\"config/experiment_config.yaml\",\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Simulation initialized!\")\n",
    "print(f\"  Patient LLM: {sim.patient_model_name or 'rule-based'}\")\n",
    "print(f\"  Doctor LLM: {sim.doctor_model_name or 'rule-based'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quick Test (1 day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running quick test: 1 day, without history\\n\")\n",
    "\n",
    "results = sim.run_experiment(\n",
    "    patient_id=\"patient_001\",\n",
    "    num_days=1,\n",
    "    condition=\"without_history\",\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Test complete!\")\n",
    "print(f\"  Conversations: {results['total_conversations']}\")\n",
    "print(f\"  Total turns: {results['total_turns']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Sample Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load conversation\n",
    "conv_dir = Path(\"data/conversations/patient_001/without_history\")\n",
    "conv_file = sorted(conv_dir.glob(\"day_*.json\"))[0]\n",
    "\n",
    "with open(conv_file, 'r') as f:\n",
    "    conv = json.load(f)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"SAMPLE CONVERSATION - Day {conv['simulation_day']}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, turn in enumerate(conv['turns'], 1):\n",
    "    speaker = \"PATIENT\" if turn['speaker'] == 'patient' else \"CHATBOT\"\n",
    "    print(f\"\\n[{i}] {speaker}:\")\n",
    "    print(turn['message'])\n",
    "\n",
    "# Show metrics\n",
    "metrics = conv.get('metrics', {}).get('automatic', {})\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Questions asked: {metrics.get('bot_questions_asked', 0)}\")\n",
    "print(f\"Info gathered: {metrics.get('key_info_gathered', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Full Experiment (Optional - Takes 30-45 min)\n",
    "\n",
    "Uncomment and run to do the full 7-day experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Running FULL experiment: 7 days, both conditions\")\n",
    "# print(\"This will take 30-45 minutes...\\n\")\n",
    "# \n",
    "# results = sim.run_full_experiment(\n",
    "#     patient_ids=[\"patient_001\"],\n",
    "#     conditions=[\"without_history\", \"with_history\"],\n",
    "#     num_days=7\n",
    "# )\n",
    "# \n",
    "# print(\"\\n✓ Experiment complete!\")\n",
    "# for r in results['results']:\n",
    "#     print(f\"  {r['patient_id']} - {r['condition']}: {r['total_turns']} turns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Create zip\n",
    "shutil.make_archive('results', 'zip', 'data')\n",
    "\n",
    "# Download\n",
    "files.download('results.zip')\n",
    "\n",
    "print(\"✓ Results downloaded!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
